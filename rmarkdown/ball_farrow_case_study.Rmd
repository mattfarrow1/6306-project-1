---
title: '6306: Case Study 1'
author: "Megan Ball, Matt Farrow"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Setup -------------------------------------------------------------------

library(tidyverse)
library(scales)
library(gt)
library(lindia)
library(maps)
library(viridis)
library(caret)
library(class)

# Load Data ---------------------------------------------------------------

beers <- read_csv(here::here("data - raw", "Beers.csv"))
beers <- janitor::clean_names(beers)

breweries <- read_csv(here::here("data - raw", "Breweries.csv"))
breweries <- janitor::clean_names(breweries)

bud_red <- "#C8102E"
```

```{r echo=FALSE, out.width="50%", fig.align='center'}
knitr::include_graphics("http://kingoftheflatscreen.com/wp-content/uploads/2015/01/budweiser-logo_1600x1200_83-standard.jpg")
```

# Background

The introduction needs to be written as if you are presenting the work to the CEO and CFO of Budweiser (your client) and that they only have had one class in statistics.  If it sounds like a student presentation, that is not acceptable.  You may assume that the CEO and CFO gave you the data and gave you the directive to report any interesting finding that you may uncover through your analysis.

# Instructions

Briefly explain the purpose of the code. The explanations should appear as a sentence or two before or after the code chunk. Even though you will not be hiding the code chunks (so that I can see the code), you need to assume that the client can’t see them.

# Analysis Questions

1. How many breweries are present in each state?

```{r breweries-per-state}
# Retrieve the states map data and merge with median data
states_map <- map_data("state")

# Breweries by state
breweries_by_st <- breweries %>% 
  count(state) %>% 
  rename(brewery_count = n,
         st = state) %>% 
  mutate(state = tolower(state.name[match(st,state.abb)])) %>% 
  filter(!is.na(state)) %>% 
  select(state, brewery_count)

# Merge states map with brewery data
breweries_by_st_map <- left_join(states_map, breweries_by_st, by = c("region" = "state"))

# Create the breweries by state map
ggplot(breweries_by_st_map, aes(long, lat, group = group)) +
  geom_polygon(aes(fill = brewery_count), color = "white") +
  scale_fill_viridis_c(option = "inferno") +
  labs(title = "Breweries by State",
       fill = "") +
  theme_void()

# Number of Breweries by State
by_st1 <- breweries_by_st %>% 
  arrange(desc(brewery_count)) %>% 
  slice(1:17)
by_st2 <- breweries_by_st %>% 
  arrange(desc(brewery_count)) %>% 
  slice(18:34)
by_st3 <- breweries_by_st %>% 
  arrange(desc(brewery_count)) %>% 
  slice(35:51) %>% 
  add_row()
bind_cols(by_st1,
          by_st2,
          by_st3) %>% 
  gt() %>% 
  tab_header(title = "How Many Breweries are Present in Each State?") %>% 
  cols_label(`state...1` = "State",
             `brewery_count...2` = "Count",
             `state...3` = "State",
             `brewery_count...4` = "Count",
             `state...5` = "State",
             `brewery_count...6` = "Count") %>%
  {.}

#Top Ten States
breweries %>% 
  count(state) %>% 
  arrange(desc(n)) %>%
  slice(1:10) %>%
  gt() %>% 
  tab_header(title = "Top 10 States") %>% 
  cols_label(state = "State",
             n = "Breweries") 

#Lowest Ten States
breweries %>% 
  count(state) %>% 
  arrange(n) %>%
  slice(1:10) %>%
  gt() %>% 
  tab_header(title = "Bottom 10 States") %>% 
  cols_label(state = "State",
             n = "Breweries") 
```

2. Merge beer data with the breweries data. Print the first 6 observations and the last six observations to check the merged file.  (RMD only, this does not need to be included in the presentation or the deck.)

```{r merge-beer-brew}
beer_brew <- left_join(beers, breweries, by = c("brewery_id" = "brew_id"))

# Clean up column names
beer_brew <- beer_brew %>% 
  rename(beer_name = name.x,
         brewery_name = name.y)

# Look at the first six observations
beer_brew %>% 
  slice_head(n = 6) %>% 
  gt() %>% 
  tab_header(title = "First Six Observations")

# Look at the last six observations
beer_brew %>% 
  slice_tail(n = 6) %>% 
  gt() %>% 
  tab_header(title = "Last Six Observations")
```

3. Address the missing values in each column.

```{r address-na}
colSums(is.na(beer_brew))

# Since our question of interest involves prediction based on abv and ibu, we may
# want to do it two ways: straight up remove the NA's and then also impute them

# Removed NA
beer_brew_noNA <- na.omit(beer_brew)
#Down to 1403 obs versus 2410

# Check to see if we should impute based on style or abv
ggplot(beer_brew, aes(abv, ibu)) +
  geom_jitter(alpha = 0.4, color = bud_red) +
  geom_smooth(method = "lm") +
  labs(title = "Relationship between ABV & IBU",
       x = "Alcohol by Volume (abv)",
       y = "International Bitterness Units (IBU)") +
  theme_minimal()

# Impute mean
impute_mean <- function(x) {
  ind_na <- is.na(x)
  x[ind_na] <- mean(x[!ind_na])
  as.numeric(x)
}

# Calculate mean ibu
beer_brew <- beer_brew %>% 
  group_by(style) %>% 
  mutate_at(vars(ibu), impute_mean)

# Replace NaN with NA
beer_brew$ibu[is.nan(beer_brew$ibu)] <- NA

# Drop remaining rows with missing values
beer_brew <- na.omit(beer_brew)
```

4. Compute the median alcohol content and international bitterness unit for each state. Plot a bar chart to compare.

```{r median-abv-ibu}
# Median ABV & IBU
median_abv_ibu <- beer_brew %>% 
  filter(state != "DC") %>% 
  group_by(state) %>% 
  summarise(median_abv = median(abv, na.rm = TRUE),
            median_ibu = median(ibu, na.rm = TRUE)) %>% 
  rename(st = state) %>% 
  mutate(state = tolower(state.name[match(st,state.abb)]),
         median_abv_per = median_abv * 100) %>% 
  ungroup() %>% 
  pivot_longer(cols = c(3,5), names_to = "measure")

colnames(median_abv_ibu)


#make two separate plots, and sort by descending

#ABV
median_abv_ibu %>%
  filter(measure == "median_abv_per") %>%
  ggplot(aes(x = reorder(state, -value), y = value)) +
  geom_bar(stat = "identity", fill = "darkolivegreen4") +
  labs(title ="Median Alcohol by Volume for Each State",
       x = "State",
       y = "ABV (%)") +
  scale_x_discrete(guide = guide_axis(angle = 90))  +
  NULL

#IBU
#make two separate plots, and sort by descending
median_abv_ibu %>%
  filter(measure == "median_ibu") %>%
  ggplot(aes(x = reorder(state, -value), y = value)) +
  geom_bar(stat = "identity", fill = "goldenrod1") +
  labs(title ="Median IBU for Each State",
       x = "State",
       y = "IBU") +
  scale_x_discrete(guide = guide_axis(angle = 90))  +
  NULL
```

## Mapping the Data Instead

```{r}
# Retrieve the states map data 
states_map <- map_data("state")

# Re-make the median_abv_ibu data set without the pivot longer and highlights
median_abv_ibu <- beer_brew %>% 
  filter(state != "DC") %>% 
  group_by(state) %>% 
  summarise(median_abv = median(abv, na.rm = TRUE),
            median_ibu = median(ibu, na.rm = TRUE)) %>% 
  rename(st = state) %>% 
  mutate(state = tolower(state.name[match(st,state.abb)]),
         median_abv_per = median_abv * 100)

# Merge the state and beer data together
median_map <- left_join(states_map, median_abv_ibu, by = c("region" = "state"))
head(median_map)


# Create the ABV map
#ggplot(median_map, aes(long, lat, group = group))+
#  geom_polygon(aes(fill = median_abv), color = "white")+
#  scale_fill_viridis_c(option = "C") +
#  labs(title = "Median ABV by State",
#       fill = "Median ABV") +
#  theme_void()

# Create the IBU map
#p <- ggplot(median_map, aes(long, lat, group = group))+
#  geom_polygon(aes(fill = median_ibu), color = "white")+
#  scale_fill_viridis_c(option = "C") +
#  labs(title = "Median IBU by State",
#       fill = "Median IBU") +
#  theme_void()


# Use the map function to get the polygon data, then find the centroids
state_poly <- map("state",  plot=FALSE, fill = TRUE)
#check state names
state_poly$names

state_centroids <- maps:::apply.polygon(state_poly, maps:::centroid.polygon)

# Create a data frame for graphing out of the centroids of each polygon
# with a non-missing name
state_centroids <- state_centroids[!is.na(names(state_centroids))]
centroid_array <- Reduce(rbind, state_centroids)
dimnames(centroid_array) <-
  list(gsub("[^,]*,", "", names(state_centroids)),
       c("long", "lat"))
label_df <- as.data.frame(centroid_array)
label_df$state <- rownames(label_df)

#remove extra names
label_df <- label_df[-c(20, 22, 34, 36, 37, 38, 40, 53, 54, 56, 57, 58, 59), ]
#remove subregion 
label_df$state <- str_extract(label_df$state, "[a-z ]+")

#join label data with median_abv_ibu value
median_map_label <- left_join(label_df, median_abv_ibu, by = c("state" = "state"))
head(median_map_label)

#Median IBU with value
ggplot(median_map, aes(long, lat, group = group)) +
  geom_polygon(aes(fill = median_ibu), color = "white") +
  geom_text(data = median_map_label,
            aes(label = round(median_ibu, digits = 1), group = state),
            size = 3) +
  scale_fill_viridis_c() +
  labs(title = "Median IBU by State",
       fill = "Median IBU") +
  theme_void()

#Median ABV with value
ggplot(median_map, aes(long, lat, group = group)) +
  geom_polygon(aes(fill = median_abv), color = "white") +
  geom_text(data = median_map_label,
            aes(label = round(median_abv_per, digits = 1), group =
                  state),
            size = 3) +
  scale_fill_viridis_c() +
  labs(title = "Median ABV by State",
       fill = "Median ABV (%)") +
  theme_void()
```

5. Which state has the maximum alcoholic (ABV) beer? Which state has the most bitter (IBU) beer?

```{r}
# Highest ABV
beer_brew %>% 
  arrange(desc(abv)) %>% 
  filter(row_number() == 1)
#Colorado

# Highest IBU
beer_brew %>% 
  arrange(desc(ibu)) %>% 
  filter(row_number() == 1)
#Oregon
```

6. Comment on the summary statistics and distribution of the ABV variable.

```{r}
summary(beer_brew_noNA)

# Histogram of ABV
beer_brew %>%
  ggplot(aes(x = abv)) +
  geom_histogram(fill = bud_red, color = "gray90") +
  scale_x_continuous(label = percent) +
  ggtitle("Distribution of ABV") +
  theme_minimal()

# Boxplot of ABV
beer_brew %>%
  ggplot(aes(x = abv)) +
  geom_boxplot(
    outlier.colour = "red",
    outlier.shape = 8,
    outlier.size = 2,
    fill = bud_red
  ) +
# #  annotate(
# #    geom = "curve",
# #    x = 0.099,
# #    y = -0.2,
# #    xend = 0.05992,
# #    yend = -0.1,
# #    curvature = .3,
#     arrow = arrow(length = unit(2, "mm"))
#   ) +
#   annotate(
#     geom = "text",
#     x = 0.1,
#     y = -0.2,
#     label = "mean (0.05992)",
#     hjust = "left"
#   ) +
#   annotate(
#     geom = "curve",
#     x = 0.079,
#     y = -0.25,
#     xend = 0.057,
#     yend = -0.15,
#     curvature = -.4,
#     arrow = arrow(length = unit(2, "mm"))
#   ) +
#   annotate(
#     geom = "text",
#     x = 0.08,
#     y = -0.25,
#     label = "median (0.057)",
#     hjust = "left"
#   ) +
#     annotate(
#     geom = "curve",
#     x = 0.12,
#     y = 0.2,
#     xend = 0.125,
#     yend = 0,
#     curvature = -.4,
#     arrow = arrow(length = unit(2, "mm"))
#   ) +
#   annotate(
#     geom = "text",
#     x = 0.108,
#     y = 0.2,
#     label = "max (0.125)",
#     hjust = "left"
#   ) +
  ggtitle("Distribution of ABV") +
  theme_minimal()
```

7. Is there an apparent relationship between the bitterness of the beer and its alcoholic content? Draw a scatter plot.  Make your best judgment of a relationship and EXPLAIN your answer.

```{r}
beer_brew %>%
  ggplot(aes(x = ibu, y = abv)) +
  geom_jitter(alpha = 0.5) +
  geom_smooth(method = "lm") +
  labs(title = "Is there a relationship Between ABV and IBU?",
       x = "IBU",
       y = "ABV") +
  theme_minimal()
```

8. Budweiser would also like to investigate the difference with respect to IBU and ABV between IPAs (India Pale Ales) and other types of Ale (any beer with “Ale” in its name other than IPA). You decide to use KNN classification to investigate this relationship. Provide statistical evidence one way or the other. You can of course assume your audience is comfortable with percentages...KNN is very easy to understand conceptually.

In addition, while you have decided to use KNN to investigate this relationship (KNN is required) you may also feel free to supplement your response to this question with any other methods or techniques you have learned. Creativity and alternative solutions are always encouraged.  

```{r}
# Create data set of just "IPA" and "Ale"
ipa_ale <- beer_brew %>% 
  mutate(style2 = case_when(str_detect(style, "IPA") ~ "IPA",
                            str_detect(style, "ale") ~ "Ale")) %>% 
  filter(!is.na(style2)) %>% 
  select(style2,
         abv,
         ibu)

# Set seed
set.seed(123)

#find optimum k for predicting beer type based on IBU and ABV
iterations = 100
numks = 30

masterAcc = matrix(nrow = iterations, ncol = numks)

for(j in 1:iterations)
{
  trainInd = sample(seq(1,642,1), .7*642)
  train = ipa_ale[trainInd,]
  test = ipa_ale[-trainInd,]
  
  for(i in 1:numks)
  {
    classifications = knn(train[,c(2,3)],test[,c(2,3)],train$style2,prob = TRUE, k = i)
    CM = confusionMatrix(table(classifications,test$style2))
    masterAcc[j,i] = CM$overall[1]
  }
  
}

MeanAcc = colMeans(masterAcc)

plot(seq(1,numks,1),MeanAcc, type = "l")
which.max(MeanAcc)

```

Based on this look for 30 different k's, we see the optimum accuracy is at k=4. However, k=5 has the same accuracy and we will use the odd value instead of tie breakers. Let's proceed to check k=5 using internal cross validation on our small data set.

```{r}

#run KNN with optimum k and internal CV
AccHolder = numeric(100)
SensHolder = numeric(100)
SpecHolder = numeric(100)

for (seed in 1:100)
{
set.seed(seed)
trainIndices = sample(seq(1:length(ipa_ale$style2)),round(.7*length(ipa_ale$style2)))
trainBeer = ipa_ale[trainIndices,]
testBeer = ipa_ale[-trainIndices,]
classifications = knn(trainBeer[,c(2,3)],testBeer[,c(2,3)],train$style2,prob = TRUE, k = 5)
CM = confusionMatrix(table(classifications,test$style2))
AccHolder[seed] = CM$overall[1]
SensHolder[seed] = CM$byClass[1]
SpecHolder[seed] = CM$byClass[2]
}

mean(AccHolder)
#Standard Error of the Mean
sd(AccHolder)/sqrt(100) 
mean(SensHolder)
#Standard Error of the Mean
sd(SensHolder)/sqrt(100) 
mean(SpecHolder)
#Standard Error of the Mean
sd(SensHolder)/sqrt(100)

```
With k=5, our average accuracy performance with 100 random splits is only 0.54. Let's revisit to find a better k.

```{r}
#run final model with k = ?

```

9. Knock their socks off! Find one other useful inference from the data that you feel Budweiser may be able to find value in. You must convince them why it is important and back up your conviction with appropriate statistical evidence. 

```{r}


```